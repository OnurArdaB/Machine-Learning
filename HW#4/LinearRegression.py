# -*- coding: utf-8 -*-
"""Copy of HW4_LinearRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iBvoXE_nC6y_3aoOwQoHOGL5mAEAQ8zD

# Load the dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt                   

df = pd.read_csv('https://raw.githubusercontent.com/OpenClassrooms-Student-Center/Evaluate-Improve-Models/master/house_prices.csv')
df.sample(5)

df.shape

"""# "Garage Area" and "SalesPrice" features are selected to analyze."""

new_df = df[['Garage Area','SalesPrice']]

"""## Convert the data into numpy arrays of two variables, X and y."""

X = np.array(new_df[['Garage Area']])
y = np.array(new_df[['SalesPrice']])
print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

"""## Split train and test data with 0.2 ratio."""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)

"""# Linear Regression
Train a linear regression.
"""

from sklearn import linear_model 

LinearModel = linear_model.LinearRegression()

LinearModel.fit(X_train,y_train)

"""## Calculate train and test R2."""

from sklearn.metrics import r2_score

y_pred_train = LinearModel.predict(X_train)
print("Train:", r2_score(y_train,y_pred_train))

y_pred_test = LinearModel.predict(X_test)
print("Test:", r2_score(y_test,y_pred_test))

"""## Print the bias and the slope."""

print('Regressor coeffient or slope:',LinearModel.coef_)
print('Interception point with axis:',LinearModel.intercept_)

"""## Plot the test set with scatter plot and add the linear regression model line.
Remember linear regression recitation.
"""

# Plot a graph with X_test vs y_test
plt.scatter(X_test, y_test);
# Regressior line showing
plt.plot(X_test, y_pred_test, color='red')
plt.show()

"""# Multiple Linear Regression
Select all features.
"""

X = df.drop(labels = ['SalesPrice'],inplace = False,axis=1)
y = df[['SalesPrice']]
print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

#import plotly.express as px
#fig = px.scatter_matrix(df)
#fig.show()

"""## Rescale the input features. Use MinMaxScaler."""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

"""## Train test split."""

x_train, x_test, y_train, y_test = train_test_split(X,y)

"""## Fit regression model."""

RegressionModel = linear_model.LinearRegression()
RegressionModel.fit(x_train,y_train)

"""## Calculate train and test R2."""

y_pred_train = RegressionModel.predict(x_train)
print("Train:", r2_score(y_train,y_pred_train))

y_pred_test = RegressionModel.predict(x_test)
print("Test:", r2_score(y_test,y_pred_test))

"""## Print the regression coefficients."""

print('Regressor coeffients for multiple linear regression:',RegressionModel.coef_)

"""## Plot the test set with scatter plot and add the linear regression model line."""

colors = ["#5129e6", "#c69d72", "#4f2920","#0a759d","#69add1","#47974e","#c9382d", "#73619c", "#411a1a","#de0ad0","#23fbf1","#f96ce6","#6b604e", "#36d0a2", "#b398ff","#8f2e11","#546920","#5c1db7","#4b0f23","#ab854e","#f5551d","#714aa1","#91e3a1", "#485946", "#42ff2f","#d3b372","#c456ec","#697deb","#bbf715","#c4bd25"]
# using the variable axs for multiple Axes
fig, axs = plt.subplots(30,10,figsize=(20,20))

for i in range(30):
  for j in range(10):
    axs[i,j].scatter(x_test[:,j*(i+1)],y_test,color=colors[i])
    axs[i,j].plot(x_test[:,j*(i+1)],y_pred_test,color="black")

"""# Ridge Regression
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html

## Use cross-validation to estimate alpha. Set the fold size to 5.
"""

from sklearn.model_selection import KFold
from sklearn.linear_model import RidgeCV
kfold = KFold(5)

alphas=[1e-3, 1e-2, 1e-1, 1, 2, 5, 8, 10]
# Create and fit model
model_rcv = RidgeCV(alphas,cv=kfold)
model_rcv.fit(x_train,y_train)

"""## Calculate the train and test R2."""

y_pred_train = model_rcv.predict(x_train)
print("Train:", r2_score(y_train,y_pred_train))

y_pred_test = model_rcv.predict(x_test)
print("Test:", r2_score(y_test,y_pred_test))

"""## Print the best alpha."""

print("Alpha:", model_rcv.alpha_)

"""## Print the regression coefficients."""

print('Regressor coeffients for ridge regression:',model_rcv.coef_)

"""## Plot the test set with scatter plot and add the ridge regression model line."""

colors = ["#5129e6", "#c69d72", "#4f2920","#0a759d","#69add1","#47974e","#c9382d", "#73619c", "#411a1a","#de0ad0","#23fbf1","#f96ce6","#6b604e", "#36d0a2", "#b398ff","#8f2e11","#546920","#5c1db7","#4b0f23","#ab854e","#f5551d","#714aa1","#91e3a1", "#485946", "#42ff2f","#d3b372","#c456ec","#697deb","#bbf715","#c4bd25"]
# using the variable axs for multiple Axes
fig, axs = plt.subplots(30,10,figsize=(20,20))

for i in range(30):
  for j in range(10):
    axs[i,j].scatter(x_test[:,j*(i+1)],y_test,color=colors[i])
    axs[i,j].plot(x_test[:,j*(i+1)],y_pred_test,color="black")