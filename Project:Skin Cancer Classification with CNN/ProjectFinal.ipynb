{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "fork-of-kernel1910868e43.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkmxUyLNswVn",
        "colab_type": "text"
      },
      "source": [
        "# Skin Cancer Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj99mtv-swVo",
        "colab_type": "text"
      },
      "source": [
        "Skin cancer is a very common condition and visual-based scans are important in the diagnosis process. Diagnosis process starts with clinical screening first.It is then followed by dermoscopic analysis, a biopsy and histopathological examination.Achieving an autonomous structure is of great importance in the aforementioned processes and involves various difficulties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OqpbJimswVo",
        "colab_type": "text"
      },
      "source": [
        "The dataset given to us has a total of 10000 images, where each image is classified with one of 5 different types of skin cancer.This dataset is available to be used for training an effective machine learning algorithm.\n",
        "\n",
        "The cancer classes mentioned are:\n",
        "\n",
        "* Melanoma (MEL)\n",
        "* Melanocytic nevus (NV)\n",
        "* Basal cell carcinoma (BCC)\n",
        "* Actinic keratosis (AK)\n",
        "* Benign keratosis (BKL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR54wESrswVp",
        "colab_type": "text"
      },
      "source": [
        "#### File descriptions\n",
        "\n",
        "Train.csv - Training data and it consists of 10,000 images along with their labels (also known as the “ground truth”)\n",
        "SkinCancerTest.csv - Testing data and it consist of 5,000 simages. Your final submission should be similar to this file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYdtIOxfswVp",
        "colab_type": "text"
      },
      "source": [
        "In this core, models will be trained to accurately match these skin cancer lesions regarding the classes they adhere to.Convolutional Neural Networks are chosen as the model in order to classify the regarding data.\n",
        "\n",
        "The kernel steps as followed:\n",
        "1. Data Analysis and Preprocessing\n",
        "    * Import necessary libraries\n",
        "    * Read and store the raw data \n",
        "    * Create a label dictionary \n",
        "    * Image Pipeline\n",
        "    * EDA (Exploratary Data Analysis)\n",
        "2. Model Building\n",
        "3. Model Training\n",
        "4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "MgBaYYdVsat7",
        "colab_type": "code",
        "colab": {},
        "outputId": "b008383a-0f08-420a-a423-6f88c2a252c7"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\"\"\"\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\"\"\"\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWls6PumswVq",
        "colab_type": "text"
      },
      "source": [
        "## 1.Data Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37BgXyAfswVq",
        "colab_type": "text"
      },
      "source": [
        "Defaultly given by kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "vqmYoc3Isat-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from PIL import Image as img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvbZ-po1swVv",
        "colab_type": "text"
      },
      "source": [
        "## Read and store the raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ5Ha9BJtPsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_prefix = \"/kaggle/input/machinelearning412-skincancerclassification/Data_SkinCancer/Data_SkinCancer/\"\n",
        "df = pd.read_csv(\"/kaggle/input/machinelearning412-skincancerclassification/Train.csv\")\n",
        "testdf = pd.read_csv(\"/kaggle/input/machinelearning412-skincancerclassification/Test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v6vcGpzKsauA",
        "colab_type": "code",
        "colab": {},
        "outputId": "73aabe8b-df4d-4e33-ed5c-43fe21bc15a6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  Category\n",
              "0  Image_1         2\n",
              "1  Image_2         2\n",
              "2  Image_3         5\n",
              "3  Image_4         2\n",
              "4  Image_5         1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hny9VHU6sauB",
        "colab_type": "text"
      },
      "source": [
        "As we can see below,there is a serious class imbalance in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TxFuyUJqsauC",
        "colab_type": "code",
        "colab": {},
        "outputId": "814d0ae4-5cd1-4b0a-8a03-d4e4e6c20a65"
      },
      "source": [
        "temp = df.groupby('Category').count()\n",
        "temp.rename(columns={'Id':'Count'})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Count\n",
              "Category       \n",
              "1          2204\n",
              "2          4489\n",
              "3          1592\n",
              "4           427\n",
              "5          1288"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kTbEmz7msauE",
        "colab_type": "code",
        "colab": {},
        "outputId": "8d7910a1-a5bc-4860-f98d-cb55e9c07562"
      },
      "source": [
        "#Printing a random image, in order to see whether I'm doing correctly or not\n",
        "#Also, I want to see image shape\n",
        "\n",
        "for i in [str(j) for j in range(1,10)]:\n",
        "    image = img.open(img_prefix+\"Image_\"+i+\".jpg\").convert(\"RGB\")\n",
        "    print(\"Image dimensions, \", np.asarray(image).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (1024, 1024, 3)\n",
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (1024, 1024, 3)\n",
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (450, 600, 3)\n",
            "Image dimensions,  (1024, 1024, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EQLCVbLsauF",
        "colab_type": "text"
      },
      "source": [
        "Ok, Image dimensions are not fixed\n",
        "We must fix the dimensions by whether shrinking the large ones or padding the small ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GrS2oQqswVx",
        "colab_type": "text"
      },
      "source": [
        "## Create a label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "68lKZz9OsauG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targetLabels={\n",
        "    1: \"MEL\",\n",
        "    2: \"NV\",\n",
        "    3: \"BCC\",\n",
        "    4: \"AK\",\n",
        "    5: \"BKL\"\n",
        "}\n",
        "df[\"CategoryNames\"]=df[\"Category\"].apply(lambda col: targetLabels[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGSR7E01swV0",
        "colab_type": "text"
      },
      "source": [
        "Labels that regards to the given Category is also inserted into the dataframe as CategoryNames columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U14FGwpzswV0",
        "colab_type": "text"
      },
      "source": [
        "## Image Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW-bRWv0swV0",
        "colab_type": "text"
      },
      "source": [
        "Despite the fact that there haven't been any EDA done on the dataset it is known that the images were not with the same sizes.\n",
        "The following function takes an image as input, resizes and normalizes the image.Finally the labels are also one hot encoded in order to use softmax layer for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "08r26-XasauI",
        "colab_type": "code",
        "colab": {},
        "outputId": "4b32f6e5-d953-4950-f517-393f9f126fff"
      },
      "source": [
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "def imagePipeline(imgPostFix):\n",
        "    return tf.cast(np.array(\n",
        "        img.open(img_prefix+imgPostFix+\".jpg\")\n",
        "                      .resize((WIDTH,HEIGHT))\n",
        "                      .convert(\"RGB\")), tf.float32)/255.0\n",
        "\n",
        "\n",
        "images = np.array(df[\"Id\"])\n",
        "target = np.array(df[\"Category\"])\n",
        "target=target-1 #[1,5] ==> [0,4]\n",
        "target = to_categorical(target)#One hot encoding labels\n",
        "target = [tf.cast(i, tf.int64) for i in target]\n",
        "target=tf.stack(target)\n",
        "images = tf.stack([imagePipeline(i) for i in images])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  Category CategoryNames\n",
              "0  Image_1         2            NV\n",
              "1  Image_2         2            NV\n",
              "2  Image_3         5           BKL\n",
              "3  Image_4         2            NV\n",
              "4  Image_5         1           MEL"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "      <th>CategoryNames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1</td>\n",
              "      <td>2</td>\n",
              "      <td>NV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2</td>\n",
              "      <td>2</td>\n",
              "      <td>NV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3</td>\n",
              "      <td>5</td>\n",
              "      <td>BKL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4</td>\n",
              "      <td>2</td>\n",
              "      <td>NV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5</td>\n",
              "      <td>1</td>\n",
              "      <td>MEL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48EYwBuzswV3",
        "colab_type": "text"
      },
      "source": [
        "Load=>Resize=>Convert To Rgb=>Create A Tensor=>Normalize\n",
        "\n",
        "Therefore image shapes become (10000, WIDTH, HEIGHT, 3)\n",
        "Label shapes become (10000, 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t-tYUZe1swV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Image dimensions, \", np.asarray(images).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVZHzWgGswV5",
        "colab_type": "text"
      },
      "source": [
        "Image dimensions are fixed after the preprocessing operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgDITFKfswV9",
        "colab_type": "text"
      },
      "source": [
        "## Activate the TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ilMewsWDsauK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ucObYNSswV5",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70EFzAenswV5",
        "colab_type": "text"
      },
      "source": [
        "Lets start with checking how the classes are distributed in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gJCDoBDoswV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = df.groupby('Category').count().drop(columns=[\"CategoryNames\"]).rename(columns={\"Id\":\"Count\"})\n",
        "plt.bar(targetLabels.values(),temp[\"Count\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVEfZ40vswV7",
        "colab_type": "text"
      },
      "source": [
        "We can see that the dataset is unbalanced so it must be considered when checking the performance of the trained model in the further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8UxwTTJpswV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = 4\n",
        "fig, m_axs = plt.subplots(5, n_samples, figsize = (4*n_samples, 3*5))\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
        "                                         df.sort_values(['CategoryNames']).groupby('CategoryNames')):\n",
        "    n_axs[0].set_title(type_name)\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
        "        c_ax.imshow(img.open(img_prefix+c_row['Id']+\".jpg\").resize((WIDTH,HEIGHT))\n",
        "                      .convert(\"RGB\"))\n",
        "        c_ax.axis('off')\n",
        "fig.savefig('category_samples.png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETX-zdZDsauM",
        "colab_type": "text"
      },
      "source": [
        "Taking the TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m7zfmOwMsauM",
        "colab_type": "code",
        "colab": {},
        "outputId": "f7bd3139-3a43-41d7-d26b-0599cd898d8c"
      },
      "source": [
        "# instantiating the model in the strategy scope creates the model on the TPU\n",
        "\"\"\" \n",
        "with tpu_strategy.scope():\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same',input_shape=(WIDTH,HEIGHT,3)))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "\n",
        "    model.add(Conv2D(128,(3,3), strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(128,(3,3), strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    model.summary()\n",
        "   \"\"\" \n",
        "\"\"\"\n",
        "with tpu_strategy.scope():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same',input_shape=(WIDTH,HEIGHT,3)))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    model.summary()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "with tpu_strategy.scope():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=6,activation='relu',padding='Same',input_shape=(WIDTH,HEIGHT,3)))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=4,activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=3, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "with tpu_strategy.scope():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same',input_shape=(WIDTH,HEIGHT,3)))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Conv2D(32,kernel_size=3, strides=2,activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64,kernel_size=3, strides=2, activation='relu',padding='Same'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2), strides=1, padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    model.summary()\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "\n",
        "    model.add(ResNet50(input_shape=(WIDTH, HEIGHT, 3), include_top=False, pooling='avg', weights=\"imagenet\"))\n",
        "    model.add(Dense(256,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(Dense(5,activation='softmax'))\n",
        "    model.layers[0].trainable = False\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                1048640   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,077,605\n",
            "Trainable params: 1,077,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nwith tpu_strategy.scope():\\n    model = tf.keras.Sequential()\\n    \\n\\n    model.add(ResNet50(input_shape=(WIDTH, HEIGHT, 3), include_top=False, pooling=\\'avg\\', weights=\"imagenet\"))\\n    model.add(Dense(256,activation=\\'relu\\'))\\n    model.add(Dropout(0.40))\\n    model.add(Dense(128,activation=\\'relu\\'))\\n    model.add(Dropout(0.40))\\n    model.add(Dense(64,activation=\\'relu\\'))\\n    model.add(Dropout(0.40))\\n    model.add(Dense(5,activation=\\'softmax\\'))\\n    model.layers[0].trainable = False\\n    model.summary()\\n\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w4L5erwxsauO",
        "colab_type": "code",
        "colab": {},
        "outputId": "b0906777-7f2e-4ad9-ad88-98ef0df9452e"
      },
      "source": [
        "optimizer=Adam(lr=0.01,beta_1=0.8,beta_2=0.999,epsilon=1e-7,decay=0.0,amsgrad=False)\n",
        "learning_reductor = ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)\n",
        "with tpu_strategy.scope():\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "    history  = model.fit(images, target, validation_split=0.2,epochs=150,verbose=1,callbacks=[learning_reductor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/150\n",
            "8000/8000 [==============================] - 14s 2ms/sample - loss: 1.3562 - accuracy: 0.4408 - val_loss: 1.2693 - val_accuracy: 0.4705\n",
            "Epoch 2/150\n",
            "8000/8000 [==============================] - 4s 463us/sample - loss: 1.2602 - accuracy: 0.4683 - val_loss: 1.2410 - val_accuracy: 0.4910\n",
            "Epoch 3/150\n",
            "8000/8000 [==============================] - 4s 467us/sample - loss: 1.2248 - accuracy: 0.4898 - val_loss: 1.1600 - val_accuracy: 0.5085\n",
            "Epoch 4/150\n",
            "8000/8000 [==============================] - 4s 459us/sample - loss: 1.1973 - accuracy: 0.5099 - val_loss: 1.1840 - val_accuracy: 0.5515\n",
            "Epoch 5/150\n",
            "8000/8000 [==============================] - 4s 468us/sample - loss: 1.1918 - accuracy: 0.5138 - val_loss: 1.1778 - val_accuracy: 0.5155\n",
            "Epoch 6/150\n",
            "8000/8000 [==============================] - 3s 431us/sample - loss: 1.1663 - accuracy: 0.5309 - val_loss: 1.1427 - val_accuracy: 0.5480\n",
            "Epoch 7/150\n",
            "7904/8000 [============================>.] - ETA: 0s - loss: 1.1366 - accuracy: 0.5453\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "8000/8000 [==============================] - 3s 409us/sample - loss: 1.1372 - accuracy: 0.5458 - val_loss: 1.1181 - val_accuracy: 0.5465\n",
            "Epoch 8/150\n",
            "8000/8000 [==============================] - 4s 462us/sample - loss: 1.1164 - accuracy: 0.5586 - val_loss: 1.0894 - val_accuracy: 0.5820\n",
            "Epoch 9/150\n",
            "8000/8000 [==============================] - 4s 445us/sample - loss: 1.0953 - accuracy: 0.5676 - val_loss: 1.0505 - val_accuracy: 0.6005\n",
            "Epoch 10/150\n",
            "8000/8000 [==============================] - 4s 467us/sample - loss: 1.0820 - accuracy: 0.5776 - val_loss: 1.0406 - val_accuracy: 0.6090\n",
            "Epoch 11/150\n",
            "8000/8000 [==============================] - 4s 498us/sample - loss: 1.0654 - accuracy: 0.5780 - val_loss: 1.0547 - val_accuracy: 0.5880\n",
            "Epoch 12/150\n",
            "8000/8000 [==============================] - 4s 454us/sample - loss: 1.0606 - accuracy: 0.5866 - val_loss: 1.0164 - val_accuracy: 0.6035\n",
            "Epoch 13/150\n",
            "8000/8000 [==============================] - 4s 465us/sample - loss: 1.0478 - accuracy: 0.5889 - val_loss: 1.0132 - val_accuracy: 0.6150\n",
            "Epoch 14/150\n",
            "8000/8000 [==============================] - 4s 470us/sample - loss: 1.0274 - accuracy: 0.5964 - val_loss: 0.9906 - val_accuracy: 0.6180\n",
            "Epoch 15/150\n",
            "8000/8000 [==============================] - 4s 502us/sample - loss: 1.0144 - accuracy: 0.5999 - val_loss: 0.9874 - val_accuracy: 0.6290\n",
            "Epoch 16/150\n",
            "8000/8000 [==============================] - 4s 454us/sample - loss: 1.0015 - accuracy: 0.6105 - val_loss: 0.9959 - val_accuracy: 0.6360\n",
            "Epoch 17/150\n",
            "8000/8000 [==============================] - 3s 437us/sample - loss: 0.9940 - accuracy: 0.6108 - val_loss: 0.9927 - val_accuracy: 0.6205\n",
            "Epoch 18/150\n",
            "8000/8000 [==============================] - 4s 441us/sample - loss: 0.9938 - accuracy: 0.6129 - val_loss: 0.9755 - val_accuracy: 0.6295\n",
            "Epoch 19/150\n",
            "8000/8000 [==============================] - 4s 439us/sample - loss: 0.9695 - accuracy: 0.6176 - val_loss: 0.9552 - val_accuracy: 0.6370\n",
            "Epoch 20/150\n",
            "8000/8000 [==============================] - 4s 477us/sample - loss: 0.9703 - accuracy: 0.6203 - val_loss: 0.9508 - val_accuracy: 0.6400\n",
            "Epoch 21/150\n",
            "8000/8000 [==============================] - 4s 448us/sample - loss: 0.9477 - accuracy: 0.6329 - val_loss: 0.9635 - val_accuracy: 0.6290\n",
            "Epoch 22/150\n",
            "8000/8000 [==============================] - 4s 460us/sample - loss: 0.9433 - accuracy: 0.6303 - val_loss: 0.9716 - val_accuracy: 0.6335\n",
            "Epoch 23/150\n",
            "8000/8000 [==============================] - 4s 451us/sample - loss: 0.9350 - accuracy: 0.6304 - val_loss: 0.9454 - val_accuracy: 0.6410\n",
            "Epoch 24/150\n",
            "8000/8000 [==============================] - 3s 437us/sample - loss: 0.9216 - accuracy: 0.6415 - val_loss: 0.9528 - val_accuracy: 0.6445\n",
            "Epoch 25/150\n",
            "8000/8000 [==============================] - 3s 426us/sample - loss: 0.9092 - accuracy: 0.6423 - val_loss: 0.9412 - val_accuracy: 0.6390\n",
            "Epoch 26/150\n",
            "8000/8000 [==============================] - 3s 429us/sample - loss: 0.9091 - accuracy: 0.6434 - val_loss: 0.9701 - val_accuracy: 0.6375\n",
            "Epoch 27/150\n",
            "7936/8000 [============================>.] - ETA: 0s - loss: 0.8940 - accuracy: 0.6453\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "8000/8000 [==============================] - 3s 431us/sample - loss: 0.8941 - accuracy: 0.6450 - val_loss: 0.9621 - val_accuracy: 0.6220\n",
            "Epoch 28/150\n",
            "8000/8000 [==============================] - 3s 429us/sample - loss: 0.8862 - accuracy: 0.6514 - val_loss: 0.9361 - val_accuracy: 0.6435\n",
            "Epoch 29/150\n",
            "8000/8000 [==============================] - 4s 466us/sample - loss: 0.8626 - accuracy: 0.6624 - val_loss: 0.9390 - val_accuracy: 0.6470\n",
            "Epoch 30/150\n",
            "8000/8000 [==============================] - 3s 432us/sample - loss: 0.8589 - accuracy: 0.6626 - val_loss: 0.9272 - val_accuracy: 0.6490\n",
            "Epoch 31/150\n",
            "8000/8000 [==============================] - 4s 442us/sample - loss: 0.8439 - accuracy: 0.6610 - val_loss: 0.9362 - val_accuracy: 0.6370\n",
            "Epoch 32/150\n",
            "8000/8000 [==============================] - 4s 493us/sample - loss: 0.8407 - accuracy: 0.6711 - val_loss: 0.9365 - val_accuracy: 0.6450\n",
            "Epoch 33/150\n",
            "7840/8000 [============================>.] - ETA: 0s - loss: 0.8325 - accuracy: 0.6709\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "8000/8000 [==============================] - 4s 467us/sample - loss: 0.8318 - accuracy: 0.6701 - val_loss: 0.9409 - val_accuracy: 0.6390\n",
            "Epoch 34/150\n",
            "8000/8000 [==============================] - 4s 462us/sample - loss: 0.8262 - accuracy: 0.6801 - val_loss: 0.9302 - val_accuracy: 0.6430\n",
            "Epoch 35/150\n",
            "8000/8000 [==============================] - 4s 489us/sample - loss: 0.8120 - accuracy: 0.6829 - val_loss: 0.9272 - val_accuracy: 0.6455\n",
            "Epoch 36/150\n",
            "7968/8000 [============================>.] - ETA: 0s - loss: 0.8098 - accuracy: 0.6797\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "8000/8000 [==============================] - 4s 460us/sample - loss: 0.8097 - accuracy: 0.6798 - val_loss: 0.9300 - val_accuracy: 0.6400\n",
            "Epoch 37/150\n",
            "8000/8000 [==============================] - 4s 447us/sample - loss: 0.8079 - accuracy: 0.6775 - val_loss: 0.9262 - val_accuracy: 0.6435\n",
            "Epoch 38/150\n",
            "8000/8000 [==============================] - 3s 421us/sample - loss: 0.7993 - accuracy: 0.6881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6b30af888e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtpu_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhistory\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearning_reductor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdXRHam3sauQ",
        "colab_type": "text"
      },
      "source": [
        "This looks promising. Thus for the next step training the model with all the data is required.\n",
        "\n",
        "Reason for this, the model is splitted to validation in order to get a adequate model.\n",
        "\n",
        "When adequate model is choosen, as it is deployed in unknown data, the train data should\n",
        "\n",
        "not be wasted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WroHdvvhsauQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "95a45f5b-db5e-47f8-949a-4e995bcd3978"
      },
      "source": [
        "optimizer=Adam(lr=0.01,beta_1=0.8,beta_2=0.999,epsilon=1e-7,decay=0.0,amsgrad=False)\n",
        "learning_reductor = ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)\n",
        "with tpu_strategy.scope():\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "    history  = model.fit(images, target, epochs=50,verbose=1,callbacks=[learning_reductor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/50\n",
            "10000/10000 [==============================] - 14s 1ms/sample - loss: 0.9534 - accuracy: 0.6207\n",
            "Epoch 2/50\n",
            "10000/10000 [==============================] - 5s 468us/sample - loss: 0.9272 - accuracy: 0.6334\n",
            "Epoch 3/50\n",
            "10000/10000 [==============================] - 5s 471us/sample - loss: 0.9233 - accuracy: 0.6382\n",
            "Epoch 4/50\n",
            "10000/10000 [==============================] - 5s 468us/sample - loss: 0.9104 - accuracy: 0.6388\n",
            "Epoch 5/50\n",
            "10000/10000 [==============================] - 5s 473us/sample - loss: 0.9043 - accuracy: 0.6439\n",
            "Epoch 6/50\n",
            "10000/10000 [==============================] - 5s 516us/sample - loss: 0.8938 - accuracy: 0.6459\n",
            "Epoch 7/50\n",
            "10000/10000 [==============================] - 5s 510us/sample - loss: 0.8818 - accuracy: 0.6515\n",
            "Epoch 8/50\n",
            "10000/10000 [==============================] - 5s 462us/sample - loss: 0.8745 - accuracy: 0.6512\n",
            "Epoch 9/50\n",
            "10000/10000 [==============================] - 5s 485us/sample - loss: 0.8731 - accuracy: 0.6566\n",
            "Epoch 10/50\n",
            "10000/10000 [==============================] - 4s 437us/sample - loss: 0.8549 - accuracy: 0.6645\n",
            "Epoch 11/50\n",
            "10000/10000 [==============================] - 5s 466us/sample - loss: 0.8506 - accuracy: 0.6625\n",
            "Epoch 12/50\n",
            "10000/10000 [==============================] - 5s 451us/sample - loss: 0.8368 - accuracy: 0.6698\n",
            "Epoch 13/50\n",
            "10000/10000 [==============================] - 5s 473us/sample - loss: 0.8317 - accuracy: 0.6703\n",
            "Epoch 14/50\n",
            "10000/10000 [==============================] - 5s 471us/sample - loss: 0.8141 - accuracy: 0.6762\n",
            "Epoch 15/50\n",
            "10000/10000 [==============================] - 4s 448us/sample - loss: 0.8233 - accuracy: 0.6716\n",
            "Epoch 16/50\n",
            "10000/10000 [==============================] - 5s 476us/sample - loss: 0.8247 - accuracy: 0.6721\n",
            "Epoch 17/50\n",
            "10000/10000 [==============================] - 5s 461us/sample - loss: 0.7846 - accuracy: 0.6906\n",
            "Epoch 18/50\n",
            "10000/10000 [==============================] - 5s 472us/sample - loss: 0.7971 - accuracy: 0.6864\n",
            "Epoch 19/50\n",
            "10000/10000 [==============================] - 5s 472us/sample - loss: 0.7775 - accuracy: 0.6919\n",
            "Epoch 20/50\n",
            "10000/10000 [==============================] - 5s 513us/sample - loss: 0.7755 - accuracy: 0.6900\n",
            "Epoch 21/50\n",
            "10000/10000 [==============================] - 5s 518us/sample - loss: 0.7780 - accuracy: 0.6877\n",
            "Epoch 22/50\n",
            "10000/10000 [==============================] - 5s 485us/sample - loss: 0.7528 - accuracy: 0.7028\n",
            "Epoch 23/50\n",
            "10000/10000 [==============================] - 5s 499us/sample - loss: 0.7480 - accuracy: 0.7009\n",
            "Epoch 24/50\n",
            "10000/10000 [==============================] - 5s 474us/sample - loss: 0.7449 - accuracy: 0.7077\n",
            "Epoch 25/50\n",
            "10000/10000 [==============================] - 5s 507us/sample - loss: 0.7308 - accuracy: 0.7033\n",
            "Epoch 26/50\n",
            "10000/10000 [==============================] - 5s 495us/sample - loss: 0.7297 - accuracy: 0.7063\n",
            "Epoch 27/50\n",
            "10000/10000 [==============================] - 5s 491us/sample - loss: 0.7301 - accuracy: 0.7033\n",
            "Epoch 28/50\n",
            "10000/10000 [==============================] - 5s 458us/sample - loss: 0.7050 - accuracy: 0.7209\n",
            "Epoch 29/50\n",
            "10000/10000 [==============================] - 4s 447us/sample - loss: 0.7208 - accuracy: 0.7140\n",
            "Epoch 30/50\n",
            "10000/10000 [==============================] - 5s 482us/sample - loss: 0.7106 - accuracy: 0.7152\n",
            "Epoch 31/50\n",
            "10000/10000 [==============================] - 5s 473us/sample - loss: 0.7095 - accuracy: 0.7148\n",
            "Epoch 32/50\n",
            "10000/10000 [==============================] - 5s 502us/sample - loss: 0.7049 - accuracy: 0.7211\n",
            "Epoch 33/50\n",
            "10000/10000 [==============================] - 5s 460us/sample - loss: 0.6832 - accuracy: 0.7225\n",
            "Epoch 34/50\n",
            "10000/10000 [==============================] - 5s 484us/sample - loss: 0.6846 - accuracy: 0.7267\n",
            "Epoch 35/50\n",
            "10000/10000 [==============================] - 5s 459us/sample - loss: 0.6844 - accuracy: 0.7269\n",
            "Epoch 36/50\n",
            "10000/10000 [==============================] - 5s 479us/sample - loss: 0.6662 - accuracy: 0.7326\n",
            "Epoch 37/50\n",
            "10000/10000 [==============================] - 5s 495us/sample - loss: 0.6711 - accuracy: 0.7369\n",
            "Epoch 38/50\n",
            "10000/10000 [==============================] - 5s 450us/sample - loss: 0.6540 - accuracy: 0.7404\n",
            "Epoch 39/50\n",
            "10000/10000 [==============================] - 5s 482us/sample - loss: 0.6419 - accuracy: 0.7426\n",
            "Epoch 40/50\n",
            "10000/10000 [==============================] - 5s 454us/sample - loss: 0.6515 - accuracy: 0.7398\n",
            "Epoch 41/50\n",
            "10000/10000 [==============================] - 5s 486us/sample - loss: 0.6319 - accuracy: 0.7455\n",
            "Epoch 42/50\n",
            "10000/10000 [==============================] - 5s 479us/sample - loss: 0.6381 - accuracy: 0.7449\n",
            "Epoch 43/50\n",
            "10000/10000 [==============================] - 5s 460us/sample - loss: 0.6321 - accuracy: 0.7481\n",
            "Epoch 44/50\n",
            "10000/10000 [==============================] - 5s 475us/sample - loss: 0.6281 - accuracy: 0.7458\n",
            "Epoch 45/50\n",
            "10000/10000 [==============================] - 5s 473us/sample - loss: 0.6294 - accuracy: 0.7484\n",
            "Epoch 46/50\n",
            "10000/10000 [==============================] - 5s 475us/sample - loss: 0.6181 - accuracy: 0.7481\n",
            "Epoch 47/50\n",
            "10000/10000 [==============================] - 4s 431us/sample - loss: 0.6101 - accuracy: 0.7520\n",
            "Epoch 48/50\n",
            "10000/10000 [==============================] - 4s 447us/sample - loss: 0.5972 - accuracy: 0.7592\n",
            "Epoch 49/50\n",
            "10000/10000 [==============================] - 4s 416us/sample - loss: 0.5892 - accuracy: 0.7586\n",
            "Epoch 50/50\n",
            "10000/10000 [==============================] - 4s 433us/sample - loss: 0.6083 - accuracy: 0.7547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ijS9hRNgsauS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testids = np.array(testdf[\"Id\"]).tolist()\n",
        "preds = np.array([], dtype=np.int32)\n",
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]\n",
        "\n",
        "for x in batch(testids, 100):\n",
        "    x = tf.stack([imagePipeline(i) for i in x])\n",
        "    prediction = model.predict(x)\n",
        "    prediction = np.argmax(prediction, axis=1)\n",
        "    prediction = prediction+1\n",
        "    preds=np.concatenate((preds, prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6pTw2_NEsauT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "header = [\"Id\", \"Category\"]\n",
        "lines = [[i, j] for i, j in zip(testids, preds)]\n",
        "with open(\"Results.csv\", \"w\", newline='') as f:\n",
        "    writer = csv.writer(f, delimiter=',')\n",
        "    writer.writerow(header)\n",
        "    for l in lines:\n",
        "        writer.writerow(l)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}